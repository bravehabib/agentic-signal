---
sidebar_position: 2
title: Data Validation Node
---

# Data Validation Node

The **Data Validation Node** checks incoming data against a [JSON Schema](https://json-schema.org/) before passing it to downstream nodes. This ensures only well-structured, expected data flows through your pipeline, reducing errors and improving reliability.

![Data Validation Node](/img/nodes/data-validation-preview.jpg)

## Configuration

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

<Tabs>
    <TabItem value="schema" label="Schema" default>
        Enter a [JSON Schema](https://json-schema.org/) to validate incoming data.  

        <details>
            <summary>Example</summary>

            ```json
            {
                "type": "object",
                "properties": {
                    "products": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "required": ["id", "title", "price"],
                        "properties": {
                        "id": { "type": "integer" },
                        "title": { "type": "string" },
                        "price": { "type": "number" }
                        }
                    }
                    }
                },
                "required": ["products"]
            }
            ```
        </details>

        ![Data Validation Node Params](/img/nodes/data-validation-params.jpg)
    </TabItem>
</Tabs>

---

## Example Usage

For example usage, see the [Product Data Validation and Visualization workflow](/docs/workflows/data/product-data-validation-and-visualization), which demonstrates fetching API data, validating it, and visualizing the results.


## Common Use Cases

1. **API Response Validation**: Ensure third-party API responses match expected formats.
2. **Input Sanitization**: Prevent malformed or incomplete data from entering your workflow.
3. **Data Quality Assurance**: Enforce required fields and data types.
4. **Error Prevention**: Catch issues early and provide feedback for correction.

## Best Practices

- **Test your schema**: Use tools like [JSON Schema Validator](https://jsonschemalint.com/) to verify your schema.
- **Be specific**: Define required fields and types to catch subtle errors.
- **Handle errors**: Use downstream nodes to handle validation failures gracefully.
- **Keep schemas up to date**: Update schemas as your data structures evolve.

## Troubleshooting

### Common Issues

- **Invalid schema**: Ensure your schema is valid JSON and follows the JSON Schema standard.
- **Unexpected validation errors**: Double-check that incoming data matches the schema.
- **Empty or missing fields**: Use `required` properties to enforce presence of important fields.

### Performance Tips

- Use for small to medium-sized data objects.
- For large datasets, validate only the necessary parts to improve performance.
- Test with sample data before running full workflows.

## Supported Data Formats

- **Input**: Any JSON object or array.
- **Output**: The original data if validation passes; an error message if validation fails.

## Why Use Data Validation?

Validating data before processing ensures that only well-structured, expected data flows through your pipeline. This reduces errors, improves reliability, and makes debugging easierâ€”especially when working with third-party APIs.
